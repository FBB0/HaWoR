# Enhanced HaWoR Training Configuration
# Comprehensive configuration for training RGB to hand mesh models

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
training_data_dir: './training_data'
validation_data_dir: './training_data'
image_size: 256
num_workers: 8
pin_memory: true
prefetch_factor: 2
persistent_workers: true

# Data augmentation
use_augmentation: true
augmentation_params:
  rotation_range: 30
  translation_range: 0.1
  scale_range: 0.2
  color_jitter: 0.2
  flip_probability: 0.5

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Backbone settings
backbone_type: 'vit'
pretrained_weights: null  # Path to pretrained weights
torch_compile: 1  # Enable PyTorch 2.0 compilation

# MANO model settings
mano_data_dir: '_DATA/data/'
mano_model_path: '_DATA/data/mano'
mano_gender: 'neutral'
num_hand_joints: 15
mano_mean_params: '_DATA/data/mano_mean_params.npz'
create_body_pose: false

# Model architecture
st_module: true
motion_module: true
st_hdim: 512
motion_hdim: 384
st_nlayer: 6
motion_nlayer: 6

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================
# Basic training settings
max_epochs: 100
batch_size: 8
learning_rate: 0.00001
weight_decay: 0.0001
min_lr: 0.0000001
grad_clip_val: 1.0

# Training schedule
warmup_epochs: 5
cosine_restarts: false
lr_decay_factor: 0.1
lr_decay_patience: 10

# Early stopping
early_stopping_patience: 15
early_stopping_min_delta: 0.0001

# Gradient accumulation
accumulate_grad_batches: 1

# =============================================================================
# LOSS CONFIGURATION
# =============================================================================
# Enhanced loss settings
use_enhanced_loss: true
use_adaptive_weights: true
temporal_window: 5

# Loss weights (adaptive if use_adaptive_weights is true)
loss_weights:
  KEYPOINTS_3D: 0.1
  KEYPOINTS_2D: 0.05
  GLOBAL_ORIENT: 0.01
  HAND_POSE: 0.01
  BETAS: 0.005
  MESH_VERTICES: 0.02
  MESH_FACES: 0.01
  TEMPORAL_CONSISTENCY: 0.005
  OCCLUSION_ROBUSTNESS: 0.01

# Loss function parameters
loss_reduction: 'mean'
use_huber_loss: true
huber_delta: 1.0
use_chamfer_loss: true
chamfer_weight: 0.1

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
# Evaluation settings
eval_every_n_epochs: 1
eval_metrics:
  - mpjpe_3d
  - mpjpe_2d
  - pck_3d_15mm
  - pck_2d_10px
  - temporal_consistency
  - mesh_quality

# Validation settings
val_check_interval: 1.0
val_batch_size: 8

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# TensorBoard logging
use_tensorboard: true
tensorboard_log_dir: './logs/tensorboard'

# Weights & Biases logging
use_wandb: false
wandb_project: 'hawor-training'
wandb_entity: null
experiment_name: 'hawor_enhanced_training'

# Logging frequency
log_every_n_steps: 50
log_images_every_n_steps: 500
log_metrics_every_n_steps: 10

# Render settings
render_log: true
render_frequency: 1000
num_render_samples: 4

# =============================================================================
# HARDWARE CONFIGURATION
# =============================================================================
# Device settings
devices: 1
accelerator: 'auto'  # auto, gpu, cpu, mps
precision: 16  # 16, 32, 64

# Memory optimization
find_unused_parameters: false
sync_batchnorm: false

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
# Output directories
output_dir: './training_output'
log_dir: './training_logs'
checkpoint_dir: './checkpoints'
report_dir: './reports'

# Checkpoint settings
save_top_k: 3
save_last: true
save_every_n_epochs: 10
monitor: 'val/loss'
mode: 'min'

# =============================================================================
# ADVANCED SETTINGS
# =============================================================================
# Mixed precision
use_amp: true
amp_level: 'O1'

# Distributed training
strategy: 'auto'  # auto, ddp, ddp_spawn, deepspeed
num_nodes: 1
sync_batchnorm: false

# Debugging
fast_dev_run: false
overfit_batches: 0
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0

# Reproducibility
deterministic: true
seed: 42

# =============================================================================
# DATASET SPECIFIC SETTINGS
# =============================================================================
# ARCTIC dataset settings
arctic_settings:
  subjects: ['s01', 's02', 's03', 's04', 's05']
  max_sequences_per_subject: 20
  min_sequence_length: 10
  max_sequence_length: 100
  
# Data filtering
data_filtering:
  min_confidence: 0.5
  max_occlusion_level: 0.8
  min_keypoint_visibility: 0.7

# =============================================================================
# OPTIMIZATION SETTINGS
# =============================================================================
# Optimizer settings
optimizer: 'adamw'
optimizer_params:
  betas: [0.9, 0.999]
  eps: 0.00000001
  amsgrad: false

# Scheduler settings
scheduler: 'cosine'
scheduler_params:
  T_max: 100
  eta_min: 0.0000001
  warmup_epochs: 5

# =============================================================================
# MONITORING SETTINGS
# =============================================================================
# Performance monitoring
monitor_gpu_memory: true
monitor_cpu_usage: true
monitor_disk_usage: true

# Alert settings
enable_alerts: false
alert_conditions:
  - metric: 'val/loss'
    threshold: 10.0
    operator: 'greater_than'
  - metric: 'train/loss'
    threshold: 0.001
    operator: 'less_than'

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================
# Experimental settings
experimental:
  use_swa: false  # Stochastic Weight Averaging
  use_ema: false  # Exponential Moving Average
  use_gradient_centralization: false
  use_lookahead: false
  
# Advanced loss functions
advanced_losses:
  use_focal_loss: false
  use_dice_loss: false
  use_contrastive_loss: false
  
# Data loading optimizations
data_loading:
  use_pin_memory: true
  use_shared_memory: true
  prefetch_factor: 2
  persistent_workers: true
